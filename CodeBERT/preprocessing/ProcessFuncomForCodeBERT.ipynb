{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://nathancooper.io/i-am-a-nerd/code/summarization/deep-learning/seq2seq/2020/12/26/Improved_Code_Commenter.html\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods_df = pd.read_json('funcom_test/comments.json')\n",
    "with open(\"comments.json\") as file:\n",
    "    dict_comments = json.load(file)\n",
    "    \n",
    "with open(\"functions.json\") as file:\n",
    "    dict_methods = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.DataFrame(dict_comments.items(), columns = ['function_id', 'comments'])\n",
    "df_methods = pd.DataFrame(dict_methods.items(), columns = ['function_id', 'methods'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_comments.shape)\n",
    "print(df_methods.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "list(dict_comments)[500000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_comments.head())\n",
    "print(df_methods.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = {'Methods': df_methods['methods'][400000:450000], 'Docstring': df_comments['comments'][400000:450000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_df=pd.DataFrame(data=dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_df.to_csv('original_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/a/27084708/5768407\n",
    "# def is_ascii(s):\n",
    "#     '''\n",
    "#     Determines if the given string contains only ascii characters\n",
    "\n",
    "#     :param s: the string to check\n",
    "#     :returns: whether or not the given string contains only ascii characters\n",
    "#     '''\n",
    "#     try:\n",
    "#         s.encode(encoding='utf-8').decode('ascii')\n",
    "#     except UnicodeDecodeError:\n",
    "#         return False\n",
    "#     else:\n",
    "#         return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df = methods_df[methods_df['Methods'].apply(lambda x: is_ascii(x))]\n",
    "# processed_df = methods_df[methods_df['Docstring'].apply(lambda x: is_ascii(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df=methods_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments_inside_mthd(mthd: str) -> str:\n",
    "    lines = mthd.split(\"\\n\")\n",
    "    eachLine = []\n",
    "    for line in lines:\n",
    "        if \"//\" in line:\n",
    "            continue\n",
    "        else:\n",
    "            eachLine.append(line)\n",
    "    \n",
    "    return \"\\n\".join(eachLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.Methods = processed_df.Methods.apply(remove_comments_inside_mthd)\n",
    "processed_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_jdocs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Remove the JavaDocs leaving only the description of the comment\n",
    "\n",
    "    :param df: the pandas dataframe to remove the JavaDocs from\n",
    "    :returns: a new pandas dataframe with the JavaDocs removed\n",
    "    '''\n",
    "    methods = []\n",
    "    comments = []\n",
    "    for i, row in tqdm(list(df.iterrows())):\n",
    "        comment = row[\"Docstring\"]\n",
    "        # Remove {} text in comments from https://stackoverflow.com/questions/14596884/remove-text-between-and-in-python/14598135\n",
    "        comment = re.sub(\"([\\{\\[]).*?([\\)\\}])\", '', comment)\n",
    "        \n",
    "        \n",
    "        cleaned = []\n",
    "        for line in comment.split('\\n'):\n",
    "            if \"@\" in line: break\n",
    "            cleaned.append(line)\n",
    "        comments.append('\\n'.join(cleaned))\n",
    "        methods.append(row[\"Methods\"])\n",
    "    new_df = pd.DataFrame(zip(methods, comments), columns = [\"Methods\", \"Docstring\"])\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = remove_jdocs(processed_df)\n",
    "processed_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse\n",
    "def clean_html(cmt: str) -> str:\n",
    "    '''\n",
    "    Remove any HTML tags from a given comment\n",
    "\n",
    "    :param cmt: the comment to remove any HTML tags from\n",
    "    :returns: the comment with any HTML tags removed\n",
    "    '''\n",
    "    result = re.sub(r\"<.?span[^>]*>|<.?code[^>]*>|<.?p[^>]*>|<.?hr[^>]*>|<.?h[1-3][^>]*>|<.?a[^>]*>|<.?b[^>]*>|<.?blockquote[^>]*>|<.?del[^>]*>|<.?dd[^>]*>|<.?dl[^>]*>|<.?dt[^>]*>|<.?em[^>]*>|<.?i[^>]*>|<.?img[^>]*>|<.?kbd[^>]*>|<.?li[^>]*>|<.?ol[^>]*>|<.?pre[^>]*>|<.?s[^>]*>|<.?sup[^>]*>|<.?sub[^>]*>|<.?strong[^>]*>|<.?strike[^>]*>|<.?ul[^>]*>|<.?br[^>]*>\", \"\", cmt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.Docstring = processed_df.Docstring.apply(clean_html)\n",
    "processed_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse\n",
    "processed_df = processed_df.applymap(lambda x: ' '.join(x.split()).lower())\n",
    "\n",
    "#processed_df = processed_df[~(processed_df['Docstring'] == '')]\n",
    "\n",
    "#processed_df = processed_df[~processed_df['Docstring'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_df = processed_df[~(processed_df['Docstring'] == '')]\n",
    "#processed_df.tail()\n",
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(cmt: str) -> str:\n",
    "    result = re.sub(r\"\\*|\\/|\\.\", \"\", cmt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.Docstring = processed_df.Docstring.apply(remove_special_characters)\n",
    "processed_df.Docstring.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['code_tokens'] = processed_df.Methods.apply(lambda x: x.split())\n",
    "processed_df['docstring_tokens'] = processed_df.Docstring.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values = []\n",
    "with open('test.jsonl', 'a') as file:\n",
    "    for i, row in processed_df.iterrows(): \n",
    "        val = {\"code\": row['Methods'], \"docstring\": row['Docstring'], \n",
    "               \"code_tokens\": row['code_tokens'], \"docstring_tokens\": row['docstring_tokens']}\n",
    "        \n",
    "        json.dump(val, file)\n",
    "        file.write('\\n')\n",
    "        #values.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
